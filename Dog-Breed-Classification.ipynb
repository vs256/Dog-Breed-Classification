{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cc94d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import datetime\n",
    "from tensorflow import summary\n",
    "from collections import OrderedDict\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "510a0ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33b925d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Windows\n",
      " Volume Serial Number is 689F-4E1C\n",
      "\n",
      " Directory of C:\\Users\\vidas\\OneDrive\\University\\Data Science Program\n",
      "\n",
      "06/15/2022  03:45 PM    <DIR>          .\n",
      "06/02/2022  07:55 PM    <DIR>          ..\n",
      "06/15/2022  02:57 PM    <DIR>          .ipynb_checkpoints\n",
      "06/15/2022  02:52 PM    <DIR>          Dog Breed Classification\n",
      "06/15/2022  03:45 PM            14,503 Dog-Breed-Classification.ipynb\n",
      "06/13/2022  04:11 PM            95,764 Lab7_PyTorch_CNNs.ipynb\n",
      "06/13/2022  05:26 PM        10,696,299 Lab7_With_Tensorboard.ipynb\n",
      "06/13/2022  05:26 PM        10,705,664 Lab8_Transfer_Learning.ipynb\n",
      "06/15/2022  03:39 PM    <DIR>          logs\n",
      "06/02/2022  07:55 PM    <DIR>          Machine-Learning-Class\n",
      "06/14/2022  04:18 PM             3,957 pytorch_finetune_tensorboard.py\n",
      "06/15/2022  02:47 PM    <DIR>          stanford-dogs-dataset\n",
      "               5 File(s)     21,516,187 bytes\n",
      "               7 Dir(s)  433,713,774,592 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c99e0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageFolder('./stanford-dogs-dataset/images/Images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1608a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20580"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset) #check how many images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d71a199b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.classes) #check how many dog breeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e53c8af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n02085620-Chihuahua', 'n02085782-Japanese_spaniel', 'n02085936-Maltese_dog']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.classes[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "add1881e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chihuahua', 'Japanese spaniel', 'Maltese dog']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Formatting\n",
    "#taking the 120 different total classes and renaming them into a nicer format.\n",
    "\n",
    "dog_breeds = []\n",
    "\n",
    "def rename(name):\n",
    "    return ' '.join(' '.join(name.split('-')[1:]).split('_'))\n",
    "\n",
    "for n in dataset.classes:\n",
    "    dog_breeds.append(rename(n))\n",
    "    \n",
    "dog_breeds[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cd7dd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a random seed so the data is reproducible in the same way\n",
    "random_seed = 42\n",
    "torch.manual_seed(random_seed);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33e1813b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12966, 1440, 6174)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split the dataset into Training, Validation, and Testing\n",
    "\n",
    "test_pct = 0.3 #test size will be 30% of dataset\n",
    "test_size = int(len(dataset)*test_pct)\n",
    "dataset_size = len(dataset) - test_size\n",
    "\n",
    "val_pct = 0.1 #validation set will be 10% of dataset\n",
    "val_size = int(dataset_size*val_pct)\n",
    "train_size = dataset_size - val_size #training set will be 90% of dataset\n",
    "\n",
    "\n",
    "train_size, val_size, test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09425817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12966, 1440, 6174)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split the training dataset\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "len(train_dataset), len(val_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b8c471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f07d0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogBreedDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, ds, transform=None):\n",
    "        self.ds = ds\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.ds[idx]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)  \n",
    "            return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe425087",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforms\n",
    "\n",
    "imagenet_stats = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")\n",
    "\n",
    "\n",
    "train_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")\n",
    "\n",
    "val_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")\n",
    "\n",
    "test_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbe5c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def imshow(img):\n",
    "  img = img / 2 + 0.5\n",
    "  np_img = img.numpy()\n",
    "  plt.imshow(np.transpose(np_img, (1, 2, 0)))\n",
    "  plt.show()\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "551bdd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DogBreedDataset(train_dataset, train_transform)\n",
    "val_dataset = DogBreedDataset(val_dataset, val_transform)\n",
    "test_dataset = DogBreedDataset(test_dataset, test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f375e855",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dl = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_dl = DataLoader(val_dataset, batch_size*2, num_workers=2, pin_memory=True)\n",
    "test_dl = DataLoader(test_dataset, batch_size*2, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efac36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def imshow(img):\n",
    "  img = img / 2 + 0.5\n",
    "  np_img = img.numpy()\n",
    "  plt.imshow(np.transpose(np_img, (1, 2, 0)))\n",
    "  plt.show()\n",
    "\n",
    "dataiter = iter(train_dl)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae02d0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    k_size = 5\n",
    "    n_input_channels = 3 # rgb\n",
    "    n_output_channels_1 = 6\n",
    "    self.conv1 = nn.Conv2d(n_input_channels, n_output_channels_1, k_size)\n",
    "    self.pool = nn.MaxPool2d(2, 2)\n",
    "    self.conv2 = nn.Conv2d(n_output_channels_1, 16, k_size)\n",
    "    self.fc1 = nn.Linear(16 * k_size * k_size, 120)\n",
    "    self.fc2 = nn.Linear(120, 84)\n",
    "    self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = self.conv1(x)\n",
    "    out = F.relu(out)\n",
    "    out = self.pool(out)\n",
    "\n",
    "    out = self.conv2(out)\n",
    "    out = F.relu(out)\n",
    "    out = self.pool(out)\n",
    "\n",
    "    out = torch.flatten(out, 1)\n",
    "\n",
    "    out = self.fc1(out)\n",
    "    out = F.relu(out)\n",
    "\n",
    "    out = self.fc2(out)\n",
    "    out = F.relu(out)\n",
    "\n",
    "    out = self.fc3(out)\n",
    "    #out = F.softmax(out, dim=1)\n",
    "    return out\n",
    "\n",
    "net = Net()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6019df6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc8a0511",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = str(datetime.datetime.now().timestamp())\n",
    "train_log_dir = 'logs/tensorboard/train/' + current_time\n",
    "val_log_dir = 'logs/tensorboard/val/' + current_time\n",
    "train_summary_writer = summary.create_file_writer(train_log_dir)\n",
    "val_summary_writer = summary.create_file_writer(val_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96c2e68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "  for epoch in range(30):\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "      inputs, labels = data\n",
    "      inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      outputs = net(inputs)\n",
    "      _, predicted = torch.max(outputs.data, 1)\n",
    "      total += labels.size(0)\n",
    "      correct += (predicted == labels).sum().item()\n",
    "\n",
    "      loss = F.cross_entropy(outputs, labels)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      running_loss += loss.item()\n",
    "             \n",
    "    with train_summary_writer.as_default():\n",
    "      summary.scalar('train loss', running_loss / i, step=epoch)\n",
    "      summary.scalar('train accuracy', correct / total, step=epoch)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "      for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    with val_summary_writer.as_default():\n",
    "      summary.scalar('validation loss', running_loss / i, step=epoch)\n",
    "      summary.scalar('validation accuracy', correct / total, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e59e383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 2088), started 0:01:15 ago. (Use '!kill 2088' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-7507cc848aa2f531\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-7507cc848aa2f531\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir ./logs/tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33745ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
